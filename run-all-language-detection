#!/usr/bin/env bash
#
# Run the record level measure of language features
#
# Input
#   The json files take place on HDFS /europeana directory
# Output
#   You should specify a file name, such as resultXX-language.csv
#   This will be the input of top level, and collection level aggregations

OUTPUT=$1
JAR_VERSION=0.6-SNAPSHOT

if [[ ("$#" -ne 1) || ("$OUTPUT" == "") ]]; then
  echo "You should add an output file (such as resultXX-language.csv)!"
  exit 1
fi

if [ -e $OUTPUT ]; then
  echo "WARNING! $OUTPUT exists, rename it to prevent overwriting the file!"
  exit 1
fi

echo "Starting language detection."

if hdfs dfs -test -d /result; then
  hdfs dfs -rm -r -f -skipTrash /result
  wait 5
fi

JAR=target/europeana-qa-spark-${JAR_VERSION}-jar-with-dependencies.jar
# spark-submit --class de.gwdg.europeanaqa.spark.LanguageCount \
#   --master local[*] \
#   $JAR \
#   hdfs://localhost:54310/europeana/*.json \
#   hdfs://localhost:54310/result \
#   data-providers.txt \
#  datasets.txt

# --inputFileName hdfs://localhost:54310/europeana/*.json \
#  --inputFileName /projects/pkiraly/2018-03-23/full/\*.json \
#  --inputFileName hdfs://localhost:54310/europeana/*.json.gz \

FORMAT="fullbean"

spark-submit --class de.gwdg.europeanaqa.spark.LanguageCount \
  --master local[*] \
  $JAR \
  --inputFileName hdfs://localhost:54310/europeana/*.json.gz \
  --outputFileName hdfs://localhost:54310/result \
  --dataProvidersFile data-providers.txt \
  --datasetsFile datasets.txt \
  --format $FORMAT \

echo Retrieve $OUTPUT
hdfs dfs -getmerge /result $OUTPUT
rm .$OUTPUT.crc

echo "Language detection is done!"
