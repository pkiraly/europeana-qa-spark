#!/usr/bin/env bash
#
# Run the record level measure of language features
#
# Input
#   The json files take place on HDFS /europeana directory
# Output
#   You should specify a file name, such as resultXX-language.csv
#   This will be the input of top level, and collection level aggregations

SECONDS=0
JAR_VERSION=0.7-SNAPSHOT
HDFS=hdfs://localhost:54310
HEADER_FILE=header-multilingual-saturation.csv

OUTPUT_FILE=
SKIP_ENRICHMENTS_FLAG=
EXTENDED_FIELD_EXTRACTION=
VERSION=
USE_HDFS=0

# read the options
TEMP=`getopt -o o:sgev: --long output-file:,skip-flag,from-gz,extended-field-extraction,version: -n 'test.sh' -- "$@"`
eval set -- "$TEMP"

# extract options and their arguments into variables.
while true ; do
    case "$1" in
        -o|--output-file)
            case "$2" in
                "") shift 2 ;;
                *) OUTPUT_FILE=$2 ; shift 2 ;;
            esac ;;
        -s|--skip-flag) SKIP_ENRICHMENTS_FLAG=--skipEnrichments ; shift ;;
        -g|--from-gz) FROM_GZ=1 ; shift ;;
        -e|--extended-field-extraction) EXTENDED_FIELD_EXTRACTION=--extendedFieldExtraction ; shift ;;
        -v|--version)
            case "$2" in
                "") shift 2 ;;
                *) VERSION=$2 ; shift 2 ;;
            esac ;;
        --) shift ; break ;;
        *) echo "Internal error!" ; exit 1 ;;
    esac
done

if [[ ("${OUTPUT_FILE}" == "") ]]; then
  echo "You should add an output file (such as resultXX-multilingual-saturation.csv)!"
  exit 1
fi

if [ -e ${OUTPUT_FILE} ]; then
  echo "WARNING! ${OUTPUT_FILE} exists, rename it to prevent overwriting the file!"
  exit 1
fi

if [ ${FROM_GZ} -eq 1 ]; then
  MASK=*.json.gz
else
  MASK=*.json
fi

FORMAT="fullbean"

echo "Starting multilingual saturation detection."
source base-dirs.sh

if [[ "$USE_HDFS" -eq 1 ]]; then
  HEADEROUTPUT=/join/${HEADER_FILE}
  HEADERCRC=.${HEADER_FILE}.crc

  if hdfs dfs -test -d /result; then
    hdfs dfs -rm -r -f -skipTrash /result
    sleep 5
  fi

  if hdfs dfs -test -d ${HEADEROUTPUT}; then
    hdfs dfs -rm -r -f -skipTrash ${HEADEROUTPUT}
    sleep 2
  fi
  HEADEROUTPUT_DIR=${HDFS}${HEADEROUTPUT}
else
  HEADEROUTPUT_DIR=join/${HEADER_FILE}
  if [ -d ${HEADEROUTPUT_DIR} ]; then
    rm -rf ${HEADEROUTPUT_DIR}
  fi
fi

JAR=target/europeana-qa-spark-${JAR_VERSION}-jar-with-dependencies.jar
#  --inputFileName $HDFS/europeana/*.json \

SOURCE_DIR=file://${BASE_SOURCE_DIR}/${VERSION}/full/${MASK}
OUTPUT_DIR=${BASE_OUTPUT_DIR}/${VERSION}/multilingual-saturation

if [ -d ${OUTPUT_DIR} ]; then
  rm -rf ${OUTPUT_DIR}
fi

spark-submit --class de.gwdg.europeanaqa.spark.MultilingualSaturation \
  --master local[*] \
  $JAR \
  --inputFileName ${SOURCE_DIR} \
  --outputFileName ${OUTPUT_DIR} \
  --headerOutputFile ${HEADEROUTPUT_DIR} \
  --dataProvidersFile data-providers.txt \
  --datasetsFile datasets.txt \
  --format $FORMAT \
  ${SKIP_ENRICHMENTS_FLAG} ${EXTENDED_FIELD_EXTRACTION}

echo Retrieve ${OUTPUT_FILE}
if [[ "$USE_HDFS" -eq 1 ]]; then
  hdfs dfs -getmerge /result ${OUTPUT_FILE}
  rm .${OUTPUT_FILE}.crc
else
  echo ${OUTPUT_DIR}/part-* | xargs cat > ${OUTPUT_FILE}
fi

echo Retrieve ${HEADER_FILE}
if [[ "$USE_HDFS" -eq 1 ]]; then
  hdfs dfs -getmerge ${HEADEROUTPUT_DIR} ${HEADER_FILE}
  sleep 2
  rm -f $HEADERCRC
  if hdfs dfs -test -d ${HEADEROUTPUT_DIR}; then
    hdfs dfs -rm -r -f -skipTrash ${HEADEROUTPUT_DIR}
    sleep 2
  fi
else
  echo ${HEADEROUTPUT_DIR}/part-* | xargs cat > ${HEADER_FILE}
fi

date +"%T"
echo "Multilingual saturation detection is done!"

duration=$SECONDS
hours=$(($duration / (60*60)))
mins=$(($duration % (60*60) / 60))
secs=$(($duration % 60))

printf "%02d:%02d:%02d elapsed.\n" $hours $mins $secs

